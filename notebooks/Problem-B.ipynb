{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"/Users/georgenteves/rec_sys_proj/data/serendipity-sac2018/movies.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.drop(['releaseDate', 'imdbId', 'tmdbId', 'Unnamed: 8','Unnamed: 9','Unnamed: 10','Unnamed: 11'], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_df = pd.read_csv(\"/Users/georgenteves/rec_sys_proj/data/serendipity-sac2018/answers.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_df = answers_df.drop(['rating', 'predictedRating', 's_ser_rel', 'q','s_ser_find','s_ser_imp','s_ser_rec', 'm_ser_rel', 'm_ser_find', 'm_ser_imp' , 'm_ser_rec'], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_rated_by_user = {}\n",
    "answers_df_timestamp_ascending = answers_df.sort_values('timestamp')\n",
    "answers_df_timestamp_ascending = answers_df_timestamp_ascending.reset_index(drop=True)\n",
    "\n",
    "for answer in range(0, len(answers_df_timestamp_ascending)):\n",
    "    if int(answers_df_timestamp_ascending['userId'][answer]) in movies_rated_by_user:\n",
    "        movies_rated_by_user[int(answers_df_timestamp_ascending['userId'][answer])].append(int(answers_df_timestamp_ascending['movieId'][answer]))\n",
    "    else:\n",
    "        movies_rated_by_user[int(answers_df_timestamp_ascending['userId'][answer])] = []\n",
    "        movies_rated_by_user[int(answers_df_timestamp_ascending['userId'][answer])].append(answers_df_timestamp_ascending['movieId'][answer])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SImilarity movies per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity_with_previous_rated_movies(user_movies_list, current_movie):\n",
    "    \n",
    "    total_similarity_sum = 0\n",
    "    total_movies_number = 0\n",
    "    \n",
    "    for movie in user_movies_list:\n",
    "        number_of_criteria = 0\n",
    "        current_similarity_sum = 0\n",
    "        \n",
    "        if (movies_df.index[movies_df['movieId'] == current_movie][0] - 1) >= 0:\n",
    "            list1 = movies_df['directedBy'][movies_df.index[movies_df['movieId'] == movie][0] - 1].split(',')\n",
    "            list2 = movies_df['directedBy'][movies_df.index[movies_df['movieId'] == current_movie][0] - 1].split(',')\n",
    "            intersection = len(list(set(list1).intersection(list2)))\n",
    "            union = (len(list1) + len(list2)) - intersection\n",
    "            current_similarity_sum += float(intersection) / union\n",
    "            number_of_criteria += 1\n",
    "\n",
    "            list1 = movies_df['starring'][movies_df.index[movies_df['movieId'] == movie][0] - 1].split(',')\n",
    "            list2 = movies_df['starring'][movies_df.index[movies_df['movieId'] == current_movie][0] - 1].split(',')\n",
    "            intersection = len(list(set(list1).intersection(list2)))\n",
    "            union = (len(list1) + len(list2)) - intersection\n",
    "            current_similarity_sum += float(intersection) / union\n",
    "            number_of_criteria += 1\n",
    "\n",
    "            list1 = movies_df['genres'][movies_df.index[movies_df['movieId'] == movie][0] - 1].split(',')\n",
    "            list2 = movies_df['genres'][movies_df.index[movies_df['movieId'] == current_movie][0] - 1].split(',')\n",
    "            intersection = len(list(set(list1).intersection(list2)))\n",
    "            union = (len(list1) + len(list2)) - intersection\n",
    "            current_similarity_sum += float(intersection) / union\n",
    "            number_of_criteria += 1\n",
    "\n",
    "            current_similarity = current_similarity_sum / number_of_criteria\n",
    "            total_similarity_sum += current_similarity\n",
    "            total_movies_number += 1\n",
    "    \n",
    "    if total_movies_number > 0:\n",
    "        answer = total_similarity_sum / total_movies_number\n",
    "    else:\n",
    "        answer = 0\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_with_previous_rated_movies_by_user(userId, current_movie):\n",
    "    similarity = 0\n",
    "    if userId in movies_rated_by_user:\n",
    "        if current_movie not in movies_rated_by_user[userId]:\n",
    "            similarity = jaccard_similarity_with_previous_rated_movies(movies_rated_by_user[userId], current_movie)\n",
    "        else:\n",
    "            previous_movies_rated_by_user = []\n",
    "            current_movie_index = movies_rated_by_user[userId].index(current_movie)\n",
    "            for movie_index in range(0, len(movies_rated_by_user[userId])):\n",
    "                if movie_index < current_movie_index:\n",
    "                    previous_movies_rated_by_user.append(movies_rated_by_user[userId][movie_index])\n",
    "                else:\n",
    "                    break\n",
    "            if len(previous_movies_rated_by_user) > 0:\n",
    "                similarity = jaccard_similarity_with_previous_rated_movies(previous_movies_rated_by_user, current_movie)  \n",
    "                \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity in ml-latest-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_ratings = pd.read_csv(\"/Users/georgenteves/rec_sys_proj/data/ml-latest-small/ratings.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_all = pd.read_csv(\"/Users/georgenteves/rec_sys_proj/data/ml-latest-small/movies.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rated_movies_popularity = {}\n",
    "\n",
    "for movie in range(0, len(movies_ratings)):\n",
    "    if int(movies_ratings['movieId'][movie]) not in rated_movies_popularity:\n",
    "        times_rated = len(movies_ratings.loc[movies_ratings['movieId'] == int(movies_ratings['movieId'][movie])])\n",
    "        rated_movies_popularity[int(movies_ratings['movieId'][movie])] = -np.log10(times_rated / movies_ratings['userId'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serendipity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = ['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8']\n",
    "movies_serendipity_sum = {}\n",
    "movies_serendipity_users = {}\n",
    "movies_serendipity = {}\n",
    "\n",
    "for answer in range(0, len(answers_df_timestamp_ascending)):\n",
    "    number_of_questions = 0\n",
    "    current_user_serendipity_sum = 0\n",
    "    \n",
    "    for question in questions:\n",
    "        if (np.isnan(answers_df_timestamp_ascending[question][answer]) == False):\n",
    "            number_of_questions += 1\n",
    "            current_user_serendipity_sum += answers_df_timestamp_ascending[question][answer]/5\n",
    "    \n",
    "    if number_of_questions != 0:\n",
    "        current_user_serendipity = current_user_serendipity_sum / number_of_questions\n",
    "    \n",
    "    if int(answers_df_timestamp_ascending['movieId'][answer]) not in movies_serendipity_sum:\n",
    "        movies_serendipity_sum[int(answers_df_timestamp_ascending['movieId'][answer])] = current_user_serendipity\n",
    "    else:\n",
    "        movies_serendipity_sum[int(answers_df_timestamp_ascending['movieId'][answer])] += current_user_serendipity\n",
    "        \n",
    "    if int(answers_df_timestamp_ascending['movieId'][answer]) not in movies_serendipity_users:\n",
    "        movies_serendipity_users[int(answers_df_timestamp_ascending['movieId'][answer])] = 1\n",
    "    else:\n",
    "        movies_serendipity_users[int(answers_df_timestamp_ascending['movieId'][answer])] += 1\n",
    "\n",
    "for movie in movies_serendipity_users:\n",
    "    movies_serendipity[movie] = movies_serendipity_sum[movie] / movies_serendipity_users[movie]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "number_of_categories = 5\n",
    "movie_ids = movies_df[\"movieId\"].unique()\n",
    "random.shuffle(movie_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = np.random.randint(low = 1,high = number_of_categories+1, size=len(movie_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_with_categories = pd.DataFrame({'Movie Id': movie_ids[:], 'Category': categories[:],'Values':np.ones(len(movie_ids))}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_movies = movies_with_categories.pivot(\n",
    "    index='Category',\n",
    "    columns='Movie Id',\n",
    "    values='Values'\n",
    ").fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = {}\n",
    "for cat_id in movies_with_categories['Category'].unique():\n",
    "    cat_dict[cat_id] = movies_with_categories.loc[movies_with_categories['Category']==cat_id]['Movie Id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymprog in /Users/georgenteves/anaconda3/lib/python3.7/site-packages (1.1.2)\n",
      "Requirement already satisfied: swiglpk>=1.4.4 in /Users/georgenteves/anaconda3/lib/python3.7/site-packages (from pymprog) (4.65.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymprog import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['directedBy'].fillna('', inplace=True)\n",
    "movies_df['starring'].fillna('', inplace=True)\n",
    "movies_df['genres'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = pd.DataFrame(\n",
    "    [int(row['userId']), int(row['movieId']), similarity_with_previous_rated_movies_by_user(int(row['userId']), int(row['movieId'])), rated_movies_popularity[int(row['movieId'])], movies_serendipity[int(row['movieId'])]] for index, row in answers_df_timestamp_ascending.iterrows() if int(row['movieId']) in rated_movies_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_df.columns = ['userId', 'movieId', 'similarity_previous_rated_by_user', 'popularity', 'movie_serendipity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.loc[(model_df.movie_serendipity >= 0.45),'movie_serendipity']= int(1)\n",
    "model_df.loc[(model_df.movie_serendipity < 0.45),'movie_serendipity']= int(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train set and test set is 1152 and 288 respectively.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(model_df, test_size = 0.2, random_state = 28)\n",
    "print ('The size of train set and test set is {0} and {1} respectively.'.format(len(train_set),len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_Y = []\n",
    "\n",
    "for index, values in train_set.iterrows():\n",
    "    train_X.append([values['similarity_previous_rated_by_user'], values['popularity']])\n",
    "    train_Y.append(values['movie_serendipity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = []\n",
    "test_Y = []\n",
    "\n",
    "for index, values in test_set.iterrows():\n",
    "    test_X.append([values['similarity_previous_rated_by_user'], values['popularity']])\n",
    "    test_Y.append(values['movie_serendipity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_regr_model = LinearRegression()\n",
    "linear_regr_model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03436054346005424"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regr_model.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgenteves/.local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9131944444444444"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_X,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08680555555555555"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test_Y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541666666666666"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "regressor = DecisionTreeClassifier(random_state = 0)  \n",
    "regressor.fit(train_X, train_Y) \n",
    "regressor.score(test_X, test_Y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14583333333333334"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(test_X)\n",
    "mean_squared_error(test_Y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minified movies categories with the 100 least popular movies of each category\n",
    "min_cat_dict = {}\n",
    "\n",
    "for cat_id in cat_dict:\n",
    "    min_cat_dict[cat_id] = []\n",
    "    current_categories_movies = pd.DataFrame(\n",
    "    [int(cat_dict[cat_id][movie_index]), rated_movies_popularity[cat_dict[cat_id][movie_index]]] for movie_index in range(0, len(cat_dict[cat_id])) if cat_dict[cat_id][movie_index] in rated_movies_popularity)\n",
    "    current_categories_movies.columns = ['movieId', 'popularity']\n",
    "    current_categories_movies_descending = current_categories_movies.sort_values(by='popularity')\n",
    "    current_categories_movies_descending = current_categories_movies_descending.reset_index(drop=True)\n",
    "    for movie in current_categories_movies_descending[0:2].iterrows():\n",
    "        min_cat_dict[cat_id].append(int(movie[1]['movieId']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies_min = []\n",
    "\n",
    "for cat_id in min_cat_dict:\n",
    "    for movie_index in range(0, len(min_cat_dict[cat_id])):\n",
    "        all_movies_min.append(min_cat_dict[cat_id][movie_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "the_users = answers_df['userId'].unique()[0:5]\n",
    "\n",
    "for index in range(0, 10):\n",
    "    if index < len(the_users):\n",
    "        params.append({\n",
    "            \"movieId\": all_movies_min[index],\n",
    "            \"userId\": the_users[index],\n",
    "            \"recommendation\": 0\n",
    "        })\n",
    "    else:\n",
    "        params.append({\n",
    "            \"movieId\": all_movies_min[index],\n",
    "            \"userId\": 0,\n",
    "            \"recommendation\": 0\n",
    "        })\n",
    "    \n",
    "x_df = pd.DataFrame(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot ratings into movie features\n",
    "x_pivot = x_df.pivot(\n",
    "    index='movieId',\n",
    "    columns='userId',\n",
    "    values='recommendation'\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "x_dict = {}\n",
    "for ind,row in x_pivot.iterrows():\n",
    "    dd = row.to_dict()\n",
    "    for us in dd:\n",
    "        if us > 0:\n",
    "            x_dict[(us,ind)] = dd[us]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict_keys = []\n",
    "for k in x_dict:\n",
    "    x_dict_keys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(117112, 110), (125112, 110), (144726, 110), (200400, 110), (205229, 110), (117112, 296), (125112, 296), (144726, 296), (200400, 296), (205229, 296), (117112, 318), (125112, 318), (144726, 318), (200400, 318), (205229, 318), (117112, 356), (125112, 356), (144726, 356), (200400, 356), (205229, 356), (117112, 480), (125112, 480), (144726, 480), (200400, 480), (205229, 480), (117112, 527), (125112, 527), (144726, 527), (200400, 527), (205229, 527), (117112, 590), (125112, 590), (144726, 590), (200400, 590), (205229, 590), (117112, 593), (125112, 593), (144726, 593), (200400, 593), (205229, 593), (117112, 1210), (125112, 1210), (144726, 1210), (200400, 1210), (205229, 1210), (117112, 2571), (125112, 2571), (144726, 2571), (200400, 2571), (205229, 2571)]\n"
     ]
    }
   ],
   "source": [
    "print(x_dict_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = {}\n",
    "for u in the_users:\n",
    "    for c in min_cat_dict:\n",
    "        for m in range(0, len(min_cat_dict[c])):\n",
    "            predicted[(similarity_with_previous_rated_movies_by_user(u, min_cat_dict[c][m]), rated_movies_popularity[min_cat_dict[c][m]])] = regressor.predict([[similarity_with_previous_rated_movies_by_user(u, min_cat_dict[c][m]), rated_movies_popularity[min_cat_dict[c][m]]]])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1: (x[205229,318] + x[205229,480] + x[205229,296] + x[205229,110] + x[205229,1210] + x[205229,590] + x[205229,356] + x[205229,593] + x[205229,2571] + x[205229,527]==2)\n",
      "R2: (x[117112,318] + x[117112,480] + x[117112,296] + x[117112,110] + x[117112,1210] + x[117112,590] + x[117112,356] + x[117112,593] + x[117112,2571] + x[117112,527]==2)\n",
      "R3: (x[144726,318] + x[144726,480] + x[144726,296] + x[144726,110] + x[144726,1210] + x[144726,590] + x[144726,356] + x[144726,593] + x[144726,2571] + x[144726,527]==2)\n",
      "R4: (x[200400,318] + x[200400,480] + x[200400,296] + x[200400,110] + x[200400,1210] + x[200400,590] + x[200400,356] + x[200400,593] + x[200400,2571] + x[200400,527]==2)\n",
      "R5: (x[125112,318] + x[125112,480] + x[125112,296] + x[125112,110] + x[125112,1210] + x[125112,590] + x[125112,356] + x[125112,593] + x[125112,2571] + x[125112,527]==2)\n",
      "R6: 0.5 * ( 0.0 * x[205229,318] + 0.0 * x[205229,480] + 0.0 * x[117112,318] + 0.0 * x[117112,480] + x[144726,318] + x[144726,480] + x[200400,318] + 0.0 * x[200400,480] + 0.0 * x[125112,318] + x[125112,480] ) >= 0.5\n",
      "R7: 0.5 * ( 0.0 * x[205229,296] + 0.0 * x[205229,110] + 0.0 * x[117112,296] + 0.0 * x[117112,110] + 0.0 * x[144726,296] + 0.0 * x[144726,110] + x[200400,296] + 0.0 * x[200400,110] + x[125112,296] + 0.0 * x[125112,110] ) >= 0.5\n",
      "R8: 0.5 * ( 0.0 * x[205229,1210] + 0.0 * x[205229,590] + 0.0 * x[117112,1210] + 0.0 * x[117112,590] + 0.0 * x[144726,1210] + x[144726,590] + 0.0 * x[200400,1210] + 0.0 * x[200400,590] + 0.0 * x[125112,1210] + 0.0 * x[125112,590] ) >= 0.5\n",
      "R9: 0.5 * ( 0.0 * x[205229,356] + 0.0 * x[205229,593] + x[117112,356] + 0.0 * x[117112,593] + x[144726,356] + x[144726,593] + x[200400,356] + 0.0 * x[200400,593] + x[125112,356] + x[125112,593] ) >= 0.5\n",
      "R10: 0.5 * ( x[205229,2571] + x[205229,527] + x[117112,2571] + x[117112,527] + 0.0 * x[144726,2571] + 0.0 * x[144726,527] + 0.0 * x[200400,2571] + 0.0 * x[200400,527] + 0.0 * x[125112,2571] + x[125112,527] ) >= 0.5\n",
      "Max : 0.5 * ( 0.0 * x[205229,318] + 0.0 * x[205229,480] + 0.0 * x[205229,296] + 0.0 * x[205229,110] + 0.0 * x[205229,1210] + 0.0 * x[205229,590] + 0.0 * x[205229,356] + 0.0 * x[205229,593] + x[205229,2571] + x[205229,527] + 0.0 * x[117112,318] + 0.0 * x[117112,480] + 0.0 * x[117112,296] + 0.0 * x[117112,110] + 0.0 * x[117112,1210] + 0.0 * x[117112,590] + x[117112,356] + 0.0 * x[117112,593] + x[117112,2571] + x[117112,527] + x[144726,318] + x[144726,480] + 0.0 * x[144726,296] + 0.0 * x[144726,110] + 0.0 * x[144726,1210] + x[144726,590] + x[144726,356] + x[144726,593] + 0.0 * x[144726,2571] + 0.0 * x[144726,527] + x[200400,318] + 0.0 * x[200400,480] + x[200400,296] + 0.0 * x[200400,110] + 0.0 * x[200400,1210] + 0.0 * x[200400,590] + x[200400,356] + 0.0 * x[200400,593] + 0.0 * x[200400,2571] + 0.0 * x[200400,527] + 0.0 * x[125112,318] + x[125112,480] + x[125112,296] + 0.0 * x[125112,110] + 0.0 * x[125112,1210] + 0.0 * x[125112,590] + x[125112,356] + x[125112,593] + 0.0 * x[125112,2571] + x[125112,527] )\n",
      "default solver: intopt\n",
      "MIP solver is set to intopt\n",
      "###>Objective value: 5.000000\n",
      "\n",
      "PyMathProg 1.0 Sensitivity Report Created: 2020/03/12 Thu 20:50PM\n",
      "================================================================================\n",
      "Variable            Activity   Dual.Value     Obj.Coef   Range.From   Range.Till\n",
      "--------------------------------------------------------------------------------\n",
      " x[117112,110]             0         -0.5            0         -inf          0.5\n",
      " x[125112,110]             0         -0.5            0         -inf          0.5\n",
      " x[144726,110]             0         -0.5            0         -inf          0.5\n",
      " x[200400,110]             0         -0.5            0         -inf          0.5\n",
      " x[205229,110]             0            0            0         -inf            0\n",
      " x[117112,296]             0         -0.5            0         -inf          0.5\n",
      " x[125112,296]             1            0          0.5          0.5          inf\n",
      " x[144726,296]             0         -0.5            0         -inf          0.5\n",
      " x[200400,296]             1            0          0.5          0.5          inf\n",
      "*x[205229,296]             0            0            0            0          0.5\n",
      " x[117112,318]             0         -0.5            0         -inf          0.5\n",
      " x[125112,318]             0         -0.5            0         -inf          0.5\n",
      " x[144726,318]             1            0          0.5          0.5          inf\n",
      "*x[200400,318]             1            0          0.5          0.5          0.5\n",
      " x[205229,318]             0            0            0         -inf            0\n",
      " x[117112,356]             1            0          0.5          0.5          inf\n",
      "*x[125112,356]             1            0          0.5          0.5          0.5\n",
      "*x[144726,356]             0            0          0.5          0.5          0.5\n",
      " x[200400,356]             0            0          0.5         -inf          0.5\n",
      " x[205229,356]             0            0            0         -inf            0\n",
      " x[117112,480]             0         -0.5            0         -inf          0.5\n",
      " x[125112,480]             0            0          0.5         -inf          0.5\n",
      " x[144726,480]             0            0          0.5         -inf          0.5\n",
      " x[200400,480]             0         -0.5            0         -inf          0.5\n",
      " x[205229,480]             0            0            0         -inf            0\n",
      " x[117112,527]             1            0          0.5          0.5          inf\n",
      " x[125112,527]             0            0          0.5         -inf          0.5\n",
      " x[144726,527]             0         -0.5            0         -inf          0.5\n",
      " x[200400,527]             0         -0.5            0         -inf          0.5\n",
      " x[205229,527]             1          0.5          0.5            0          inf\n",
      " x[117112,590]             0         -0.5            0         -inf          0.5\n",
      " x[125112,590]             0         -0.5            0         -inf          0.5\n",
      " x[144726,590]             1            0          0.5          0.5          inf\n",
      " x[200400,590]             0         -0.5            0         -inf          0.5\n",
      " x[205229,590]             0            0            0         -inf            0\n",
      " x[117112,593]             0         -0.5            0         -inf          0.5\n",
      " x[125112,593]             0            0          0.5         -inf          0.5\n",
      " x[144726,593]             0            0          0.5         -inf          0.5\n",
      " x[200400,593]             0         -0.5            0         -inf          0.5\n",
      " x[205229,593]             0            0            0         -inf            0\n",
      " x[117112,1210]            0         -0.5            0         -inf          0.5\n",
      " x[125112,1210]            0         -0.5            0         -inf          0.5\n",
      " x[144726,1210]            0         -0.5            0         -inf          0.5\n",
      " x[200400,1210]            0         -0.5            0         -inf          0.5\n",
      " x[205229,1210]            0            0            0         -inf            0\n",
      "*x[117112,2571]            0            0          0.5            0          0.5\n",
      " x[125112,2571]            0         -0.5            0         -inf          0.5\n",
      " x[144726,2571]            0         -0.5            0         -inf          0.5\n",
      " x[200400,2571]            0         -0.5            0         -inf          0.5\n",
      " x[205229,2571]            1          0.5          0.5            0          inf\n",
      "================================================================================\n",
      "Note: rows marked with a * list a basic variable.\n",
      "\n",
      "================================================================================\n",
      "Constraint       Activity Dual.Value  Lower.Bnd  Upper.Bnd RangeLower RangeUpper\n",
      "--------------------------------------------------------------------------------\n",
      " R1                     2          0          2          2          2          3\n",
      " R2                     2        0.5          2          2          2          3\n",
      " R3                     2        0.5          2          2          2          3\n",
      " R4                     2        0.5          2          2          1          2\n",
      " R5                     2        0.5          2          2          1          2\n",
      "*R6                     1          0        0.5        inf          1          1\n",
      "*R7                     1          0        0.5        inf          1          1\n",
      "*R8                   0.5          0        0.5        inf        0.5        0.5\n",
      "*R9                     1          0        0.5        inf          1          1\n",
      "*R10                  1.5          0        0.5        inf        1.5        1.5\n",
      "================================================================================\n",
      "Note: normally, RangeLower is the min for the binding bound, and RangeUpper\n",
      "gives the max value. However, when neither bounds are binding, the row is\n",
      "marked with a *, and RangeLower is the max for Lower.Bnd(whose min is -inf),\n",
      "and RangeUpper is the min for Upper.Bnd(whose max value is inf). Then the\n",
      "columns of RangeLower, RangeUpper and Activity all have identical values.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model('assign') is not the default model."
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "begin(\"assign\")\n",
    "verbose(True)  # be verbose\n",
    "x = var('x', x_dict_keys, bool)\n",
    "\n",
    "for u in the_users: sum(x[u,min_cat_dict[c][m]] for c in min_cat_dict for m in range(0, len(min_cat_dict[c]))) == 2 \n",
    "for c in min_cat_dict: (1/len(min_cat_dict[cat_id]))*sum(predicted[(similarity_with_previous_rated_movies_by_user(u, min_cat_dict[c][m]), rated_movies_popularity[min_cat_dict[c][m]])]*x[u,min_cat_dict[c][m]] for u in the_users for m in range(0, len(min_cat_dict[c]))) >= 0.5\n",
    "maximize((1/len(min_cat_dict[cat_id]))*sum(predicted[(similarity_with_previous_rated_movies_by_user(u, min_cat_dict[c][m]), rated_movies_popularity[min_cat_dict[c][m]])]*x[u,min_cat_dict[c][m]] for u in the_users for c in min_cat_dict for m in range(0, len(min_cat_dict[c]))))\n",
    "solver(int, \n",
    "    #this branching option often helps \n",
    "    br_tech=glpk.GLP_BR_PCH, \n",
    ")\n",
    "solve() # solve the model\n",
    "print(\"###>Objective value: %f\"%vobj())\n",
    "sensitivity() # sensitivity report\n",
    "end() #Good habit: do away with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
